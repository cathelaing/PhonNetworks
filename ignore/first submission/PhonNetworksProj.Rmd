---
title: "Phonological Networks and Systematicity in Early Lexical Acquisition"
author:
- name: Catherine E. Laing
  affiliation: '1'
  corresponding: yes
  address: Department of Language and Linguistic Science, University of York, Heslington, YO10 5DD.
  email: catherine.laing@york.ac.uk
authornote: |
 All code and associated data for this manuscript can be found at https://github.com/cathelaing/PhonologicalNetworks.  This study was not pre-registered.
shorttitle: Systematicity in early phonological development
output:
  papaja::apa6_pdf: default
  #extra_dependencies: ["float"]
  #papaja::apa6_word: default
abstract: "Infants' early words tend to be phonologically similar. This may reflect a systematic approach to early production, as they adapt newly-acquired forms to fit familiar structures in the output. This 'rich-get-richer' approach to phonological acquisition, known as *preferential attachment* in network science, proposes that new words cluster together with existing phonologically-similar words in the lexicon (or network). This contrasts with recent work (e.g. Fourtassi et al., 2020) showing that the learning environment is the key predictor in learning (*preferential acquisition*). This study expands on previous analyses of vocabulary norm data to analyse naturalistic data, namely phonetic transcriptions of nine infants' word productions, from word onset to age 2;6. Network growth models test whether 1) acquisition is best modelled through preferential attachment or preferential acquisition, 2) the trajectory of network growth changes over time, and 3) there are any differences in network growth of adult target forms vs. infants' actual productions. Results show that preferential attachment predicts acquisition of new words more convincingly than preferential acquisition: newly-acquired words are phonologically similar to existing words in the network. Furthermore, systematicity is most apparent in early acquisition, and infants produce their early words more systematically than we would expect from looking at target forms alone."
keywords: systematicity, phonological development, preferential attachment, networks analysis
#wordcount: "" 
bibliography: Systematicity.bib
#floatsintext: yes
figsintext: no
figurelist: yes
tablelist: no
footnotelist: no
linenumbers: no
numbersections: false
mask: no
draft: no
documentclass: apa6
header-includes:
-  \DeclareDelayedFloatFlavor{kableExtra}{table}
- \usepackage{tipa}
#- \newfontfamily\PF{Arial}
classoption: man
affiliation:
- id: '1'
  institution: University of York, York, UK
latex_engine: xelatex
---

```{r setup, include=FALSE}

source("prelims.R")
r_refs(file="r-references.bib")


my_citations <- cite_r(
  file="r-references.bib"
  , pkgs=c("tidyverse", "igraph", "papaja", "lmerTest")
  , withhold=FALSE
  , footnote=TRUE
)

# load files

globalthresholds_AOP <- feather::read_feather("Data/globalthresholds_AOP.feather")
full_thresholds <- feather::read_feather("Data/full_thresholds.feather")

regression_data_lyon <- feather::read_feather("Data/regression_data_lyon.feather")
regression_data_providence <- feather::read_feather("Data/regression_data_providence.feather")
regression_data <- rbind(regression_data_lyon, regression_data_providence)

comparison_data_P <- read_csv("Data/comparison_data_providence.csv")                                                            
comparison_data_L <- read_csv("Data/comparison_data_lyon.csv")
comparison_data <- rbind(comparison_data_P, comparison_data_L)

source("PhonologicalNetworks-Figures.R")
source("PhonologicalNetworks-Tables.R")

stat_sum_df <- function(fun, geom="crossbar", ...) {
  stat_summary(fun.data=fun, colour="red", geom=geom, width=0.2, ...)
}

```

Decades of work on phonological development has documented the systematic nature of infants' earliest words. Studies of phonetic [@mccune_early_2001] and phonological structures [@vihman_prosodic_2016] show that many of a child's first word forms share similar properties. Infants draw on what they know: when articulatory, memory and planning capacities are simultaneously limited, a "phonic core of remembered lexical items and articulations" [@ferguson_words_1975, p.112] may help them deal with the challenge of developing an early lexicon. Vihman [-@vihman_phonological_2019, p.263] describes the early lexicon as "an emergent network of related forms" that develops systematically, in line with the well-rehearsed segments and structures already in the infant's inventory. A networks approach to phonological development offers one way of identifying and quantifying this systematicity. In this study, I present a longitudinal analysis of nine infants' lexical development to identify systematicity in the first three years of word production. I consider the phonological characteristics of the developing lexicon using network analysis to demonstrate how early systematicity may support infants to acquire the requisite capacity for flexible and automatic word production.

In early development, the combined challenges of articulation, memory and planning mean that the constraints on infants' production are high, and so they draw on a limited set of vocal outputs that represent a growing number of target words. According to Vihman [-@vihman_phonological_2014; -@vihman_phonological_2019], word production begins with a small lexicon of phonologically-simple and accurately-produced forms, which are 'selected' for their ease of production, as well as their perceptual salience. As the lexicon grows, target forms that do not necessarily fit these structures are 'adapted' so that they do. Selection of and adaption to accessible phonological structures indicate the presence of systematicity within the developing lexicon. Essentially, the new target form is allocated to one of a small number of accessible or well-rehearsed motoric categories, and as these categories increase in size they become increasingly entrenched [@thelen_esther_dynamic_1996]. In data from their bilingual (English-Spanish) daughter’s early word acquisition, Deuchar and Quay [-@deuchar_bilingual_2000] show that 13 of her first 20 words are produced with a CV structure, and many are phonologically identical: she produces *car*, *clock*, *casa* ‘house’ and *cat* as [ka], and *papa* ‘daddy’, *pájaro* ‘bird’ and *panda* as [pa]. This demonstrates a 'pattern force', whereby production is driven by a small number of well-rehearsed structures. This tendency to acquire similar-sounding forms may continue throughout development: Mitchell, Tsui and Byers-Heinlein [-@mitchell_cognates_2022] show that French-English bilingual infants are more likely to acquire translation equivalents that are similar in phonological form (cognates, e.g. *banana* and *banane*) than non-cognate word pairs (e.g. *dog* and *chien*) upto age 27 months. Systematicity in phonological acquisition may thus support lexical development over the first three years.

One way of interrogating systematicity in early phonological productions is through network analysis, which offers a quantitative perspective on the organization and development of the lexicon. Developmental research in this area centres around the words that children target in production to establish connectivity on phonological [e.g. @siew_investigation_2020] and semantic [e.g. @hills_longitudinal_2009] planes. That is, how similar target words are to one another in form or meaning, and what this might mean for acquisition. However, as yet there is no work looking at the way children *produce* those words; that is, whether or not children are drawing on systematicity in the output. Given the extensive background research that suggests a systematic approach to early word *production*, expanding network analysis to this area is a natural next step for language development networks. 

The term *network* refers to a web of forms (or *nodes*, in network terms) that are interconnected based on shared properties. Here these are phonological properties, but could also be semantic, or indeed non-linguistic properties such as genetic information, social connections or location [see @bell_network_2017, for a review]. Network growth models analyse changes within a system over time, and two key models[^1] of development have been proposed for lexical acquisition: preferential attachment (hereafter **PAT**) and preferential acquisition [hereafter **PAQ**, @hills_longitudinal_2009; see also @steyvers_large-scale_2005-2]. PAT models of network growth propose a rich-get-richer scenario, whereby the most highly-connected nodes (nodes with more *edges*) in the network are most likely to attract new nodes. In phonological development terms, this model implies that the lexicon will constitute clusters of similar-sounding words, and that a child is more likely to acquire new words that attach to these dense clusters: infants' production of newly-acquired words will be similar to their production of existing words in the lexicon. PAT-like growth is therefore driven by the *internal* linguistic system. On the other hand, PAQ-like growth assumes that forms that connect to (i.e. share properties with) a higher number of *different* nodes in the existing network will be acquired first. PAQ models of network growth thus assume that *external* factors in the learning environment influence acquisition -- that is, words that are most well-connected within the target language will be acquired earlier. In phonological terms, this would mean that early productions would constitute a more even distribution of segments and structures, resembling the statistical properties of the ambient language more closely, rather than a 'pattern force' driven by dominant features of the existing lexicon. 

Existing studies show mixed evidence for PAT- and PAQ-like growth[^2] in lexical development. Hills and colleagues' [-@hills_longitudinal_2009] study of semantic networks showed evidence for PAQ, but not PAT, in associative networks of normed vocabulary acquisition data. Amatuni and Bergelson [-@amatuni_semantic_2017] support this with an analysis of a large-scale corpus of input data combined with normed productive vocabulary data derived from WordBank [@frank_wordbank_2017]. These same approaches have also been applied to phonological data: Fourtassi, Bian and Frank [-@fourtassi_growth_2020] analyse both phonological and semantic network growth from vocabulary norms (receptive and productive) in 10 languages to find consistent evidence in support of PAQ-like growth, for both phonological and semantic networks, receptive and productive vocabularies, and across the 10 languages included in their analysis. In contrast, Siew and Vitevitch [-@siew_investigation_2020] tested phonological networks in acquisition of older Dutch- and English-learning children (age 3-9 years), again using vocabulary norms to indicate age of acquisition for each word. Their analysis revealed contrasting findings for English compared with Dutch, as well as an age effect: PAT-like network growth predicted acquisition in English and Dutch, and both PAQ and a third model (Lure of the Associates, not discussed here) predicted word learning in Dutch. PAT was a better predictor of acquisition earlier on in development (i.e. earlier-acquired words were likely to attach to densely-connected clusters of similar forms); later on, the opposite was found, whereby later-acquired words tended to be phonologically more distinct (i.e. less similar to existing words in the network). Evidence in favour of PAT has also been found in adult word-learning experiments: for example, Mak and Twitchell's [-@mak_evidence_2020] work with paired-association learning in adults shows that participants were better at remembering word pairs when items had been paired with highly-connected cue words in semantic space. The authors propose that highly-connected words may support learning due to the fact that they tend to be used more flexibly, and thus occur in a more diverse set of linguistic contexts. In infancy, this relates back to Ferguson and Farwell's "phonic core of remembered lexical items and articulations" [@ferguson_words_1975, p.112], as infants apply the same well-rehearsed phonological form flexibly and systematically to new items in the lexicon.

These studies present an intersection of evidence for the role of PAT and PAQ network growth in phonological development. However, two key aspects of these existing approaches should be expanded further. First, the consideration of acquisition in terms of only target forms provides no view of systematicity in *production*, which is where systematicity has been most well-documented in naturalistic data. Second, vocabulary norming data abstracts away from the individual differences expected in early phonological development [e.g. @vihman_external_1994]; by drawing on data that generalises across hundreds (or even thousands) of children, it may not be possible to capture developing systematicity due to individual differences in the words and sounds that are acquired first. This makes it difficult to test which model of network growth (PAT or PAQ) is most cogent. To better understand the role of systematicity in early word production, it is essential to consider infants' *actual productions* of their early word forms, in terms of both *how* and *when* they produce them. In this paper, I analyse phonological networks of both *target* and *actual forms* (that is, the words children produce, and the way they produce them) produced in naturalistic data from two languages, in order to consider phonological systematicity within the individual development trajectories of nine infants. 

# Hypotheses

Drawing on naturalistic data, this study uses network growth models to capture phonological connectivity (taken here as an index of systematicity) within the individual lexicons of nine infants. Two  sets of networks will be established for each infant: one tracing connections between infants' *actual* word productions, the other between the *target* productions of these forms. Network analysis will quantify systematicity in the developing lexicon via two key network growth frameworks: PAT and PAQ. I will draw on approaches outlined in previous studies [@amatuni_semantic_2017; @fourtassi_growth_2020; @siew_investigation_2020] to test whether naturalistic data reveals evidence of systematicity in infants' output forms, such that language development is shaped by existing production knowledge. Specifically, I predict that:

H1) Developing phonological networks will show stronger evidence of a PAT-like model of growth over a PAQ-like model, based on evidence from the phonological development literature that shows phonological similarity across individual infants' lexicons [e.g. @vihman_emergence_2013].

H2) PAT-like growth will be most evident earlier on in development, as infants select and then adapt words to fit their production capacity [@vihman_phonological_2019]. Later, more variability is expected as phonological capacity develops. This would also align with previous evidence for PAT-like growth in toddlers [@siew_investigation_2020] and novel word learning in adults [@mak_evidence_2020].

H3) If PAT-like growth is supported in the data, then this should be more convincing for Actual than Target productions, given that we expect infants to adapt target words to fit the motor routines that are most accessible to them in production. This difference is not expected for a PAQ-like model of network growth, which assumes that network growth reflects connectivity in the input; PAQ thus assumes that Actual and Target networks do not differ.

To test these hypotheses, phonological networks will be established for nine infants acquiring American English or French. Phonological distance will be calculated between each word and each other word in each infant's network to establish connectivity within the network. Logistic regression models and Generalized Additive Mixed Models (GAMMs) will determine whether acquisition of *Actual* and *Target* forms reflects PAT- or PAQ-like growth in early phonological development, and how these networks change over time.


# Methods

This analysis follows approaches taken by Hills and colleagues [-@hills_longitudinal_2009] and Siew and Vitevitch [-@siew_investigation_2020], by establishing network growth values for each word in each child's lexicon. Logistic regression models will be used to test whether PAT or PAQ growth values can best predict word learning. This is followed with the use of Generalized Additive Mixed Models (GAMMs) to analyse the trajectory of network growth values over time.

## Data and Materials

Data for this study was extracted from CHILDES [Child Language Data Exchange System, @macwhinney_childes_2000] using Phon [@hedlund_gregory_phon_2020]. Two corpora were selected for the analysis: American English [Providence corpus, @demuth_word-minimality_2006] and French [Lyon corpus, @demuth_katherine_prosodically-conditioned_2008]. These corpora were selected due to their parallel data collection and transcription methods. The English data includes five infants (including two boys[^3]) and four from the French corpus (two boys). Both corpora include spontaneous interactions between child and caregiver, recorded in the home for one hour every two weeks from the onset of first words. The original corpora were orthographically transcribed, and then phonetically transcribed and checked by trained coders. See Demuth et al. [-@demuth_word-minimality_2006] and Demuth and Tremblay [-@demuth_katherine_prosodically-conditioned_2008] for full details of data collection and annotation.

Transcripts were extracted from the first session in the dataset (the first session in which the child produced a word) until age 2;6. Data was analysed on a month-by-month basis, such that all new word types produced in each month were aggregated to give a rolling monthly network of all words produced by each child. The session in which a word first occurred was considered the session in which it was 'acquired', and and was included in that month's list of newly-acquired words. Later productions of the same word were not included in the dataset. Two of the American infants (Naima and Lily) had denser data taken at weekly intervals during some periods of data collection, but this is not considered to be an issue as no between-child comparisons will be conducted, and subject will be coded as a random effect in all statistical models. The total network of words at any given month amounts to all the unique words produced up to and including that month. All tokens of each newly-acquired word produced by each infant in each session were extracted (*Actual* forms, i.e., the phonological form as produced by the child) alongside their target transcription (*Target* forms).

```{r data overview}
types.corpus <- regression_data %>%
  group_by(corpus, Speaker) %>%
  distinct(gloss1, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

types <- regression_data %>%
  group_by(Speaker) %>%
  distinct(gloss1, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

tokens <- regression_data %>%
  summarise(mean_tok=mean(n_tokens),
            sd_tok = sd(n_tokens))

syls <- comparison_data %>%
  distinct(Gloss, Speaker, .keep_all = T) %>%
  group_by(corpus) %>% 
  summarise(mean_syl = mean(nsyl_target),
              sd_syl = sd(nsyl_target),
              max_syl = max(nsyl_target))

nsyls <- comparison_data %>%
    distinct(Gloss, Speaker, .keep_all = T) %>%
  group_by(corpus, nsyl_target) %>%
  tally() %>%
  pivot_wider(names_from = corpus, values_from = n)

syl.4 <- subset(nsyls, nsyl_target == 4)$French
```
Only words included on the US English and French communicative development inventories [CDIs, @fenson_variability_1994; @kern_sophie_ifdc_2010] were analysed. Following Jones and Brandt [-@jones_children_2019], every unique word was considered, though plurals were categorised with their singular nouns. For example, *fall*, *fell* and *falling* were considered as unique words (coded under the CDI 'basic level' *fall*), while *bananas* was categorised with its singular form *banana* and *children* with *child*. In the French data, this rule was also applied to masculine/feminine forms: *animaux* was categorised with the singular *animal*, and feminine *petite* was categorised with masculine *petit*. Words with the same basic level form that were orthographically different but phonologically indistinguishable (e.g. verb forms in French, such as *aime* and *aiment* from the infinitive *aimer* 'to love') were categorised together. This approach was taken in order to account for developmental changes in infants' word production (i.e. the production of more complex morphological forms) while also avoiding coding two words as different that share almost identical forms and meanings (e.g. plural nouns).

To generate networks of Actual and Target forms, phonological distance was calculated between every word and every other word in the cumulative network at each month, following Monaghan, Christiansen, Farmer and Fitneva's [-@monaghan_measures_2010] approach. This is based on phonological features, following Harm and Seidenberg [-@seidenberg_dyslexia_1999] and based on Chomsky and Halle's [-@chomsky_noam_sound_1968] theory of government phonology. This was considered to be the most appropriate measure of phonological distance, as oppose to other established measures such as Levenshtein distance [e.g. @fourtassi_growth_2020; @siew_investigation_2020]: distinctive features allow us to consider distance on a phonologically-appropriate gradient, whereby the difference between words such as *bat* and *pat* is smaller than the difference between *bat* and *rat*. Using edit distance as a measure, *pat*, *bat* and *rat* would be equidistant, thereby equating all phonemes as articulatorily similar, which does not reflect the reality of phonological development: /p/ and /b/ are among the earliest consonants to be acquired, whereas /r/ is not typically acquired until around age 5 [cf. @mcleod_childrens_2018]. Note that in the present analysis only consonants were included, given that vowels are highly variable in production until around age 3, and notoriously difficult to transcribe from child speech [@donegan_normal_2013; @kent_what_2020]. When multiple tokens of the same word type were produced in a single session, the values derived from the distinctive feature matrix were averaged across tokens to create a mean phonological representation for each word type. While this is not a perfect measure, it captures a metric of both variability and similarity within and between each word type.

The final dataset includes `r round(types$n)` word types overall, aggregated across infants (English=`r round(subset(types.corpus, corpus == "English")$n)`, French=`r round(subset(types.corpus, corpus == "French")$n)`). On average, there were `r round(tokens$mean_tok)` tokens of each word type (SD = `r round(tokens$sd_tok)`). See Table \@ref(tab:table-data-overview) for a breakdown by corpus and child. All but `r syl.4` tokens (all French) in the data had three syllables or fewer in the target form, with `r round(subset(syls, corpus == "English")$mean_syl)` syllable on average in the English data (SD = `r round(subset(syls, corpus == "English")$sd_syl,2)`) and `r round(subset(syls, corpus == "French")$mean_syl,2)` in the French data (SD = `r round(subset(syls, corpus == "French")$sd_syl,2)`). 

```{r table-data-overview, echo=F, message=FALSE, warning=FALSE, comment=F}
cap="Age (months) at first session, number of sessions and number of distinct word types produced by each child in the dataset. Means and SDs for each corpus are shown in bold."
#apa_table(table.data.overview, caption=cap, col_spanners=NULL, digits=0, placement="H", font_size="small")
kable(table.data.overview, "latex", booktabs=T, longtable=T, 
      caption=cap, digits=0, align="c")  %>%  # might need to turn digits back to 0
  kable_styling()%>%
  row_spec(4, bold=F, hline_after=T) %>%
  row_spec(5, bold=T, hline_after=F) %>%
  row_spec(6, bold=T, hline_after=T) %>%
  row_spec(11, bold=F,hline_after=T) %>%
  row_spec(12, bold=T,hline_after=F) %>%
  row_spec(13, bold=T,hline_after=T) %>%  
  row_spec(14, bold=T,hline_after=F) %>%
  row_spec(15, bold=T,hline_after=F)
```

## Network Analysis

For each child, two kinds of network were generated: 1) a *global network*, which represents the final network, i.e. all words produced in the data by 2;6. This network includes the Target production of all individual word types produced in the dataset, coded for age of first production. The global network is taken to reflect the learning environment, or the input, which is why only Target forms are included; this will be used to establish PAQ growth values for each word in the data (see below), and also serves as a proxy for the 'end-state' towards which each child's phonological development is directed. 2) A series of 'known' networks representing the lexicon at each month. Each monthly known network includes all the words produced up to and including the given month, in either Actual (the infants' realization) or Target (the target realization) form. This series of networks is used to generate PAT values for each word in the data. As a reminder, for both kinds of networks, a given word type was included from the first session in which it occurred, and multiple tokens of a given word type in that session were 'averaged out' to one unique value for each word. Connectivity was established between all words in the global network, and all words in each monthly network; two nodes were considered to be connected (i.e., formed an edge) if they had a scaled phonological distance of 0.25 or less; this value captures the lower quartile of connectivity within the data.

```{r network comparison}

ntargetactual <- globalthresholds_AOP %>% group_by(data_type) %>% tally()
network_diff <- nrow(full_thresholds) - nrow(globalthresholds_AOP)

```

Once networks were established, PAT and PAQ values were calculated for each word. Following Siew and Vitevitch's [-@siew_investigation_2020] approach, these values were generated by computing, for each month, the likelihood that an as-yet-unknown word (i.e. all the words in the global network that had not yet been produced) would form an edge with known words in the existing network (i.e. the words produced up to and including a given month). The PAT value of a given yet-to-be-learned word represents the mean degree of all the words it would connect to (i.e. those with a phonological distance of 0.25 or less) if it were learned in the following month. For example, a word with a PAT value of 5.6 would connect to a set of words in the following month that, on average, connected to 5.6 other words each. Given that PAT assumes that newly-acquired words will connect to already-well-connected words in the existing network, higher PAT values predict learning in the following month: new words will connect to words with higher mean degrees. PAT networks were generated with both Actual and Target forms. PAQ values reflect the degree of a given word in the global network of all words produced by 2;6. So a word with a PAQ value of 87 connects to 87 other words in the global network. Again, as PAQ predicts that well-connected words in the global network would be acquired earlier, higher PAQ values predict earlier learning; in each month, we would expect that as-yet-unknown words with the highest PAQ values will be acquired in the following month. As PAQ-like growth is assumed to represent the connectivity of words in the ambient language, global networks were established with Target forms only. Note that, as both PAT and PAQ values are established through connectivity in the network (i.e. only words that form an edge with another word are represented), not all words are included in the analysis; `r (network_diff)` words did not connect to any other word at a threshold of 0.25. For the same reason, the size of Actual (n = `r (subset(ntargetactual, data_type == "actual")$n)`) and Target (n = `r (subset(ntargetactual, data_type == "target")$n)`) networks differs, as some forms connected at a threshold of 0.25 in their Actual, but not their Target, forms.

## Data Analysis

### Network growth models
Network growth models will be used to address the first two hypotheses. Network growth models are logistic regression models that predict whether or not a word is learned in the following month; the dependent variable is whether or not a word was learned in month *n*+1 (learned vs. not learned). The key predictors of acquisition are PAT/PAQ growth values for each word at each month. The models test the assumption that higher growth values predict earlier learning, such that words with higher PAT/PAQ values at month *n* are more likely to be learned at month *n*+1. Following predictions set out in H1, model comparisons should show PAT values to be a better predictor of word learning than PAQ values. H2 predicts age-related changes in the effect of PAT; a PAT x Age interaction is expected to show PAT to be a better predictor of learning at earlier time-points. 

### GAMMs
It is also a possibility that any age-related changes will be non-linear. To address this, Generalized Additive Mixed Models (GAMMs) will be used to test H2, following Wieling [-@wieling_analyzing_2018] and Sóskuthy [-@soskuthy_generalised_2017]. GAMMs allow analysis of dynamically varying data (i.e. change over time), without assuming change to be linear. Since there is no clear expectation as to whether any age-related changes would be linear or not, testing H2 using both logistic regression and GAMMs will account for both possibilities. Non-linearity in the data is analysed in the model through the inclusion of *smooth terms* and *random smooths*, which capture the non-linearity of fixed and random effects, respectively, alongside parametric terms. The dependent variable in these models will be PAT and PAQ values (tested as predictors in the network growth models outlined above); if predictions set out in H2 are borne out in the data, then we would expect to see a significant effect for age on PAT/PAQ values as a smooth in the model. H3 will also be tested using GAMMs, given that any differences between Actual and Target data may change over time. Here, we would expect to see a significant effect for Data type as a parametric term. These effects will be identified through nested model comparison and inspection of smooth plots. Full model details are provided below.

All code for data preparation and analysis can be found on the project's GitHub repository at https://github.com/cathelaing/PhonologicalNetworks. This study was not pre-registered.

## Results

### Age of production (AoP) ~ connectivity

```{r aop-degree correlations, message=FALSE, warning=FALSE, include=FALSE}

stats.corr.all <- table.aop.deg.corr.speaker %>% summarise(mean_rho=mean(rho),
                                                      sd_rho=sd(rho))

stats.corr_Providence <- globalthresholds_AOP %>%
        group_by(Speaker, corpus) %>%
        summarize(rho=stats::cor.test(AOP, degree, method="sp")$estimate,
                  pval=stats::cor.test(AOP, degree, method="sp")$p.value
                  ) %>%
        ungroup() %>% group_by(corpus) %>%
  summarise(mean_rho=mean(rho),
            sd_rho=sd(rho)) %>%
  filter(corpus == "English")

stats.corr_Lyon <- globalthresholds_AOP %>%
        group_by(Speaker, corpus) %>%
        summarize(rho=stats::cor.test(AOP, degree, method="sp")$estimate,
                  pval=stats::cor.test(AOP, degree, method="sp")$p.value
                  ) %>%
        ungroup() %>% group_by(corpus) %>%
  summarise(mean_rho=mean(rho),
            sd_rho=sd(rho)) %>%
  filter(corpus == "French")

```

First, to assess the broader assumption that connectivity in the network will change systematically over time, regardless of whether that is through PAT- or PAQ-like changes, correlations were established between age of production (AoP) and degree across the dataset. Across all infants, there was a mean AoP~degree correlation of *r*=`r round(stats.corr.all$mean_rho,3)` (Spearman's, *SD*=`r printnum(stats.corr.all$sd_rho)`; English: *r*=`r round(stats.corr_Providence$mean_rho,3)`, *SD* =`r printnum(stats.corr_Providence$sd_rho)`; French: *r*=`r round(stats.corr_Lyon$mean_rho,3)`, *SD*=`r printnum(stats.corr_Lyon$sd_rho)`); overall, later-learned words were less well-connected in the networks. Negative correlations were found in all children's data; these were all significant at *p*<.05 except Anais (French corpus). See Table S1 and Figure S1 (Supplementary data).

### Network growth models

Next, network growth models were generated to test whether PAT and PAQ values predicted which words were produced in the following month. As a reminder, models of both PAT- and PAQ-like acquisition predict that, for each month, the as-yet-unknown words with the highest PAT/PAQ values should be learned in the following month. 

Logistic mixed effects regression models included a binomial dependent variable (coded as 0 or 1) indexing whether, for each as-yet-unknown word at month *n*, it was acquired in month *n+1*. As well as PAT and PAQ growth values, each model included target word length in phonemes, the word's frequency in mothers' speech in the corpus, the number of tokens of each word produced by the child in the month it was acquired, aggregated monthly vocabulary size, word category, corpus (English vs. French), and age as fixed effects. Infant was specified as a random effect, with a by-subject random slope for the effect of age. All relevant variables were scaled and centered. P-values were established through nested model comparisons. Analysis of Actual/Target data includes PAT values for the Actual/Target network, respectively; PAQ values always represent the Target network (i.e. to simulate the adult production of a given word in the input), but models were run on both Actual and Target data since connectivity in these data sets differed over time. These models were run using the *lme4()* package [@R-lme4] in R [@R-base].

Following Siew and Vitevitch [-@siew_investigation_2020], the first step was to construct three models: a null model (model 0) with word length, frequency, n tokens, word category, vocabulary size, corpus, and age included as predictors of word learning, and then two additional models with PAT (model 1) and PAQ (model 2) growth values included as additional predictors, respectively. In each case interactions were included between Word length x Age, Word frequency x Age, n Tokens x Age, Vocabulary size x Age and PAT/PAQ values x Age. Models 1 and 2 were then compared against model 0 to test for the effects of PAT and PAQ values individually. A third model (model 3) was then constructed that included both PAT and PAQ values as predictors. Data type (Actual and Target) was modeled separately in each case. The full model specification for model 3 is as follows:

*Model 3*: Learned next ~  PAQ value * Age +
                PAT value * Age +
                Word length * Age +
                Word frequency * Age +
                n Tokens * Age +
                Vocab size * Age +
                Category +
                Corpus +
                (1 + Age|Speaker)

```{r regression model actual, message=FALSE, warning=FALSE, include=FALSE}

reg_dat <- regression_data[which(complete.cases(regression_data[,c('PAQ_scaled_target', 'PAT_scaled', 'length_scaled', 'freq_scaled', 'age_scaled', 'corpus')])),]

model0_A <- glmer(learned_next ~
                    length_scaled*age_scaled +
                    tokens_scaled*age_scaled +
                    freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                    corpus +
                    category +
                    (1+age_scaled|Speaker),
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                           # specifiying optimizer to support convergence (does not converge without this)
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "actual"))

model1_A <- glmer(learned_next ~
                  length_scaled*age_scaled +
                    tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                   corpus +
                    category +
                    PAT_scaled*age_scaled +
                    (1+age_scaled|Speaker), 
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "actual"))

model2_A <- glmer(learned_next ~
                  length_scaled*age_scaled +
                    tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                    corpus +
                    category +
                    PAQ_scaled_target*age_scaled +
                    (1+age_scaled|Speaker),
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "actual"))


models01_A <- anova(model0_A, model1_A)
models02_A <- anova(model0_A, model2_A)

model3_A <- glmer(learned_next ~
                    length_scaled*age_scaled +
                    tokens_scaled*age_scaled +
                      freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                    corpus +
                    category +
                    PAQ_scaled_target*age_scaled +
                      PAT_scaled*age_scaled +
                    (1+age_scaled|Speaker),
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "actual"))

models13_A <- anova(model1_A, model3_A)
models23_A <- anova(model2_A, model3_A)

#summary(model3_A)

table.A.model.output <- rbind(models01_A, models02_A, models13_A, models23_A) %>%
  rownames_to_column(var="Model") %>%
  filter(Chisq > 0) %>%
  rename("p"=`Pr(>Chisq)`) %>%
  mutate(Model=fct_recode(Model,
                           "null vs. PAT"="model1_A",
                            "null vs. PAQ"="model2_A",
                            "PAT vs. PAT+PAQ"="model3_A",
                            "PAQ vs. PAT+PAQ"="model3_A1"),
             p=scales::pvalue(p)
        ) %>%
  select(Model, `Df`, `Chisq`, `p`)

model.summary_A <- summary(model3_A)

model3_A_tab <- model.summary_A$coefficients %>%
  as.data.frame %>%
  rename(
    "b"="Estimate"
     , "SE"="Std. Error"
     , "z"="z value"
     , "p"="Pr(>|z|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  )

table.model3_A <- model3_A_tab %>%
  printnum(
    digits=c(2, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  select(Effect, `b`, `SE`, `z`, `p`) %>%
  rename("beta"=`b`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `z`=as.numeric(`z`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p))
```
```{r regression model Target, message=FALSE, warning=FALSE, include=FALSE}

model0_T <- glmer(learned_next ~
                    length_scaled*age_scaled +
                    tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                   corpus +
                    category +
                    (1+age_scaled|Speaker), 
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "target"))



model1_T <- glmer(learned_next ~
                  length_scaled*age_scaled +
                  tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                  corpus +
                  category +
                  PAT_scaled*age_scaled +
                  (1+age_scaled|Speaker),
                  family=binomial("logit"),
                  control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "target"))

model2_T <- glmer(learned_next ~
                  length_scaled*age_scaled +
                  tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                  corpus +
                  category +
                  PAQ_scaled_target*age_scaled +
                  (1+age_scaled|Speaker),
                  family=binomial("logit"),
                  control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                  data=subset(reg_dat, data_type == "target"))


models01_T <- anova(model0_T, model1_T)
models02_T <- anova(model0_T, model2_T)

model3_T <- glmer(learned_next ~
                  length_scaled*age_scaled +
                  tokens_scaled*age_scaled +
                  freq_scaled*age_scaled +
                    vocab_scaled*age_scaled +
                  corpus +
                  category +
                  PAQ_scaled_target*age_scaled +
                  PAT_scaled*age_scaled +
                  (1+age_scaled|Speaker),
                    family=binomial("logit"),
                    control=glmerControl(calc.derivs=FALSE,
                                         optimizer="bobyqa",
                                         optCtrl=list(maxfun=2e5)),
                    data=subset(reg_dat, data_type == "target"))

models13_T <- anova(model1_T, model3_T)
models23_T <- anova(model2_T, model3_T)

#summary(model3_T)

table.T.model.output <- rbind(models01_T, models02_T, models13_T, models23_T) %>%
  rownames_to_column(var="Model") %>%
  filter(Chisq > 0) %>%
  rename("p"=`Pr(>Chisq)`) %>%
  mutate(p=scales::pvalue(p)
         ) %>%
  select(`Df`, `Chisq`, `p`)

table.model.outputs <- cbind(table.A.model.output, table.T.model.output)

model.summary_T <- summary(model3_T)

model3_T_tab <- model.summary_T$coefficients %>%
  as.data.frame %>%
  rename(
    "b"="Estimate"
     , "SE"="Std. Error"
     , "z"="z value"
     , "p"="Pr(>|z|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  )

table.model3_T <- model3_T_tab %>%
  printnum(
    digits=c(2, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  select(Effect, `b`, `SE`, `z`, `p`) %>%
  rename("beta"=`b`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `z`=as.numeric(`z`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p))

rownames(table.model3_T) <- NULL

table.model.3 <- cbind(table.model3_A, table.model3_T)
table.model.summary <- table.model.3[,-6]

table.model.summary <- table.model.summary %>% mutate(Effect=fct_recode(Effect,
                                               Age="Age scaled",
                                               Length="Length scaled",
                                               `n Tokens` = "Tokens scaled",
                                              `Word frequency`="Freq scaled",
                                              `Vocab size` = "Vocab scaled",
                                              `Corpus` = "CorpusFrench",
                                              `PAQ value`="PAQ scaled target",
                                              `PAT value`="PAT scaled",
                                              `Age x Length`="Length scaled $\\times$ Age scaled",
                                              `Age x n Tokens` = "Age scaled $\\times$ Tokens scaled",
                                              `Age x Frequency`="Age scaled $\\times$ Freq scaled",
                                              `Age x Vocab size`="Age scaled $\\times$ Vocab scaled",
                                              `Age x PAQ`="Age scaled $\\times$ PAQ scaled target",
                                              `Age x PAT`="Age scaled $\\times$ PAT scaled")) %>%
  filter(!(grepl("Category", Effect, ignore.case = TRUE)))

rownames(table.model.summary) <- NULL
  

actual_beta_PAT <- subset(model3_A_tab, Effect == "PAT scaled")$b
actual_beta_PAQ <- subset(model3_A_tab, Effect == "PAQ scaled target")$b
actual_p_PAT <- subset(model3_A_tab, Effect == "PAT scaled")$p
actual_p_PAQ <- subset(model3_A_tab, Effect == "PAQ scaled target")$p

target_beta_PAT <- subset(model3_T_tab, Effect == "PAT scaled")$b
target_beta_PAQ <- subset(model3_T_tab, Effect == "PAQ scaled target")$b
target_p_PAT <- subset(model3_T_tab, Effect == "PAT scaled")$p
target_p_PAQ <- subset(model3_T_tab, Effect == "PAQ scaled target")$p

```

```{r table-model-outputs, echo=FALSE, message=FALSE, warning=FALSE}
cap="Outputs from nested model comparisons comparing logistic regression models predicting acquisition of words in each month according to PAT- and PAQ-like growth structures."
kable(table.model.outputs, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c",
      col.names=c("Model", "Df", "Chi Sq", "p", "Df", "Chi Sq", "p")) %>%
    kable_styling()%>%
  add_header_above(c(" "=1, "Actual"=3, "Target"=3)) %>%
  row_spec(4, hline_after=T)
```

```{r table-data-summary, echo=F, message=FALSE, warning=FALSE, comment=F}
cap="Results from maximal logistic regression model (model 3) testing the effects of network growth values, corpus (English as baseline), word frequency, vocabulary size, word category, n tokens and word length to predict word acquisition. All variables were scaled and centred. Category has been removed for ease of interpretation but is shown in the full model output in S2."
knitr::kable(table.model.summary, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c",
          col.names=gsub("[.1]", "", names(table.model.summary))) %>%
  add_header_above(c(" "=1, "Actual"=4, "Target"=4))
```

In the Actual and Target data, PAT values improved model fit over and above the effects of word frequency, word length, n tokens, vocabulary size, category, corpus, and age, whereas PAQ values did not. See Table \@ref(tab:table-model-outputs). When PAQ values were added to the model testing just PAT values, model fit was improved over and above the effects of PAT alone in the Target, but not the Actual, data. When PAT values were added to the model testing only PAQ values, model fit was improved in both Actual and Target data. PAT was thus a better predictor of acquisition in the Actual data (since PAQ did not improve fit of any models), while both PAT and PAQ contributed to acquisition in the Target data.

Model outputs are shown in Table \@ref(tab:table-data-summary). In both Actual and Target data, higher PAT values predicted acquisition (Actual data: *b*=`r printnum(actual_beta_PAT)`, *p* `r printp(actual_p_PAT)`; Target data: *b*=`r printnum(target_beta_PAT)`, *p*=`r printp(target_p_PAT)`), providing support for H1. Alongside PAT values, word frequency, n tokens, vocabulary size and age were all significant predictors of acquisition in both Actual and Target data: less frequent words were more likely to be learned, as were words with a higher token count. Somewhat counter-intuitively, lower vocabulary size but higher age both predicted learning, likely because a word is both more likely to be added to a smaller vocabulary (i.e. it hasn't been produced before) but, if it hasn't already been learned, as-yet-unknown words are increasingly likely to be learned in the following month, and this likelihood increases over time. Corpus and word category predicted learning in the Target data only; a word was significantly more likely to be acquired in the following month in the English (Target) data, likely because the English corpus was larger than the French corpus (see Table \@ref(tab:table-data-overview)). Category has been removed the Table \@ref(tab:table-data-summary) for ease of reading, but is shown in the full model output in the SI (S2). 

Word frequency, n tokens and vocabulary size all interacted significantly with age in both Actual and Target data: higher-frequency words were acquired earlier, as were words with lower token counts. As can be expected, vocabulary size was smaller at earlier ages. Interactions with PAT and PAQ values will be explored below. 

### PAT-like growth over time

```{r GAMM prep, echo=F, message=FALSE, warning=FALSE, comment=F}

reg_data <- subset(regression_data, age == (AOP-1))

reg_dat_actual <- subset(reg_data, data_type == "actual")
reg_dat_target <- subset(reg_data, data_type == "target")

reg_dat_actual$start.event <- reg_dat_actual$session_ordinal == 1 
reg_dat_target$start.event <- reg_dat_target$session_ordinal == 1 

```

H2 predicted a change in PAT-like growth over time, such that PAT values should predict learning more effectively in earlier acquisition than later acquisition. That is, earlier words should have higher PAT values relative to vocabulary size than later-acquired words. The models reported above show significant PAT x Age interactions for both Actual and Target data, as well as a significant PAQ x Age interaction in the Target data (see Table \@ref(tab:table-data-summary)). However, the direction of this effect is not as expected: in the Actual data, PAT values of newly-learned words are lower earlier on in development, while they are higher in the Target data. In the Target data, PAQ values of newly-learned words were lower at earlier ages. 

To explore these results further, GAMMs were run using the *mgcv()* package in R [@R-mgcv_a]. PAT values were included as the dependent variable in the model, with PAQ values as a fixed effect. Otherwise, models incorporated the same fixed effects and interactions as in the mixed-effects regression models above. By-infant and by-corpus random smooths were included in the model for the effect of age; these control for by-infant and by-corpus differences in the data over time. To account for the fact that adjacent values (i.e. PAT values at month *n* and month *n+1*) were likely correlated, an autocorrelation parameter was included, which was derived from an initial full model. The start point for each infant's dataset (i.e. their first recording session) was also indexed in the model. To test for the effect of age, model comparisons were run using the *compareML()* function from the *itsadug()* package [@R-itsadug]: the full model included the effect of age as a smooth term, as well as interactions between age and PAQ values, word frequency, word length, number of tokens, and vocabulary size. This was compared to another model that did not include the effect of age in either smooth terms or interactions. Because model summaries for GAMM smooths may be non-conservative [@soskuthy_generalised_2017], any significant effects in the initial model comparisons will be assessed using smooth plots of the models. Given that a PAQ x Age interaction was identified in the Target data, the same models will also be run with PAQ values as the dependent variable (and PAT values as a fixed effect). This component of the analysis will be exploratory given that we have no expectation as to how PAQ values will affect learning over time. As above, Actual and Target data were modeled separately; the data was subsetted such that only the PAT values at the time-point immediately prior to first production were analysed, in order to represent the point at which learning took place. This left `r nrow(reg_dat_actual)` data points for the Actual data, and `r nrow(reg_dat_target)` for the Target data.

```{r GAMM age actual PAT, message=FALSE, warning=FALSE, include=FALSE}

PAT.gamm.base_A <- bam(PAT_scaled ~ 
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAQ_target, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAQ_target) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, by=Speaker, bs="cr") +
                       s(AOP, by=corpus, bs="cr"),
                     dat=reg_dat_actual, method="ML")

rA <- start_value_rho(PAT.gamm.base_A) 

PAT.gamm.1_A <- bam(PAT_scaled ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAQ_target, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAQ_target) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                         ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),  
                        data = reg_dat_actual, method = "ML", 
                        rho=rA, AR.start=reg_dat_actual$start.event)

PAT.gamm.0_A <- bam(PAT_scaled ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                      s(PAQ_target, bs = "cr") +
                       # s(AOP, bs = "cr") +                       
                       # ti(AOP, PAQ_target) +
                       # ti(AOP, freq_scaled) + 
                       # ti(AOP, length_scaled) +
                       # ti(AOP, tokens_scaled) +
                       # ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),  
                    data = reg_dat_actual, method = "ML", 
                    rho=rA, AR.start=reg_dat_actual$start.event)

PAT.gamm.actual <- compareML(PAT.gamm.1_A, PAT.gamm.0_A)
PAT.gamm.A <- PAT.gamm.actual$table

PAT.gamm.A_summ <- summary(PAT.gamm.1_A)

```

```{r GAMM age target PAT, message=FALSE, warning=FALSE, include=FALSE}

PAT.gamm.base_T <- bam(PAT_scaled ~ 
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAQ_target, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAQ_target) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, by=Speaker, bs="cr") +
                       s(AOP, by=corpus, bs="cr"),
                     dat=reg_dat_target, method="ML")

rT <- start_value_rho(PAT.gamm.base_T) 

PAT.gamm.1_T <- bam(PAT_scaled ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAQ_target, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAQ_target) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                         ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),  
                        data = reg_dat_target, method = "ML", 
                        rho=rT, AR.start=reg_dat_target$start.event)

PAT.gamm.0_T <- bam(PAT_scaled ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAQ_target, bs = "cr") +
                       # s(AOP, bs = "cr") +                       
                       # ti(AOP, PAQ_target) +
                       # ti(AOP, freq_scaled) + 
                       # ti(AOP, length_scaled) +
                       # ti(AOP, tokens_scaled) +
                       #   ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),  
                    data = reg_dat_target, method = "ML", 
                    rho=rT, AR.start=reg_dat_target$start.event)

PAT.gamm.target <- compareML(PAT.gamm.1_T, PAT.gamm.0_T)
PAT.gamm.T <- PAT.gamm.target$table

PAT.gamm.A.summ <- summary(PAT.gamm.1_A)
PAT.gamm.T.summ <- summary(PAT.gamm.1_T)

```

```{r GAMM age actual PAQ, message=FALSE, warning=FALSE, include=FALSE}

PAQ.gamm.base_A <- bam(PAQ_scaled_target ~ 
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAT_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, by=Speaker, bs="cr") +
                       s(AOP, by=corpus, bs="cr"),
                     dat=reg_dat_actual, method="ML")

rA <- start_value_rho(PAT.gamm.base_A) 

PAQ.gamm.1_A <- bam(PAQ_scaled_target ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAT_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                         ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),  
                        data = reg_dat_actual, method = "ML", 
                        rho=rA, AR.start=reg_dat_actual$start.event)

PAQ.gamm.0_A <- bam(PAQ_scaled_target ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       # s(AOP, bs = "cr") +                       
                       # ti(AOP, PAT_scaled) +
                       # ti(AOP, freq_scaled) + 
                       # ti(AOP, length_scaled) +
                       # ti(AOP, tokens_scaled) +
                       #   ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9),   
                    data = reg_dat_actual, method = "ML", 
                    rho=rA, AR.start=reg_dat_actual$start.event)

PAQ.gamm.actual <- compareML(PAQ.gamm.1_A, PAQ.gamm.0_A)
PAQ.gamm.A <- PAQ.gamm.actual$table
PAQ.gamm.A_summ <- summary(PAQ.gamm.1_A)

```

```{r GAMM age target PAQ, message=FALSE, warning=FALSE, include=FALSE}

PAQ.gamm.base_T <- bam(PAQ_scaled_target ~ 
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAT_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, by=Speaker, bs="cr") +
                       s(AOP, by=corpus, bs="cr"),
                     dat=reg_dat_target, method="ML")

rT <- start_value_rho(PAT.gamm.base_T) 

PAQ.gamm.1_T <- bam(PAQ_scaled_target ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       s(AOP, bs = "cr") +                       
                       ti(AOP, PAT_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                         ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9), 
                        data = reg_dat_target, method = "ML", 
                        rho=rA, AR.start=reg_dat_target$start.event)

PAQ.gamm.0_T <- bam(PAQ_scaled_target ~ 
                      corpus +
                      category +
                      s(freq_scaled, bs = "cr") + 
                      s(length_scaled, bs = "cr") +
                      s(tokens_scaled, bs = "cr") + 
                      s(vocab_scaled, bs = "cr") +
                       s(PAT_scaled, bs = "cr") +
                       # s(AOP, bs = "cr") +                       
                       # ti(AOP, PAT_scaled) +
                       # ti(AOP, freq_scaled) + 
                       # ti(AOP, length_scaled) +
                       # ti(AOP, tokens_scaled) +
                       #   ti(AOP, vocab_scaled) +
                      s(AOP, corpus, bs="fs", m=1, k=2) +
                      s(AOP, Speaker, bs="fs", m=1, k=9), 
                    data = reg_dat_target, method = "ML", 
                    rho=rA, AR.start=reg_dat_target$start.event)

PAQ.gamm.target <- compareML(PAQ.gamm.1_T, PAQ.gamm.0_T)
PAQ.gamm.T <- PAQ.gamm.target$table

PAQ.gamm.T_summ <- summary(PAQ.gamm.1_T)

```

```{r GAMM data type PAT, message=FALSE, warning=FALSE, include=FALSE}

DT.gamm.base <- bam(PAT_scaled ~ data_type +
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAQ_scaled_target, bs = "cr") +
                       s(AOP, bs = "cr") +   
                       s(AOP, by = data_type) + 
                       ti(AOP, PAQ_vocab_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, by=data_type, bs="cr") +
                       s(AOP, by=Speaker, bs="cr") +
                       s(AOP, by=corpus, bs="cr"),
                     dat=reg_data, method="ML")

rDT <- start_value_rho(DT.gamm.base) 
#summary(DT.gamm.1)

DT.gamm.1 <- bam(PAT_scaled ~ data_type +
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAQ_scaled_target, bs = "cr") +
                       s(AOP, bs = "cr") +    
                       s(AOP, by = data_type) +                       
                       ti(AOP, PAQ_vocab_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, corpus, bs="fs", m=1, k=2) +
                       s(AOP, data_type, bs="fs", m=1, k=2) +
                       s(AOP, Speaker, bs="fs", m=1, k=9),  
                       dat=reg_data, method="ML",
                        rho=rDT, AR.start=reg_data$start.event)

DT.gamm.0 <- bam(PAT_scaled ~ #data_type +
                       corpus +
                       category +
                       s(freq_scaled, bs = "cr") + 
                       s(length_scaled, bs = "cr") +
                       s(tokens_scaled, bs = "cr") + 
                       s(vocab_scaled, bs = "cr") +
                       s(PAQ_scaled_target, bs = "cr") +
                       s(AOP, bs = "cr") +   
                       #s(AOP, by = data_type) + 
                       ti(AOP, PAQ_vocab_scaled) +
                       ti(AOP, freq_scaled) + 
                       ti(AOP, length_scaled) +
                       ti(AOP, tokens_scaled) +
                       ti(AOP, vocab_scaled) +
                       s(AOP, corpus, bs="fs", m=1, k=2) +
                       #s(AOP, data_type, bs="fs", m=1, k=2) +
                       s(AOP, Speaker, bs="fs", m=1, k=9),  
                       dat=reg_data, method="ML",
                        rho=rDT, AR.start=reg_data$start.event)


gamm.data.type <- compareML(DT.gamm.1, DT.gamm.0)
gamm.DT <- gamm.data.type$table

DT.gamm.summ <- summary(DT.gamm.1)
Estimate_DT <- as.data.frame(DT.gamm.summ$p.coeff) %>%
  rownames_to_column() %>%
  filter(rowname == "data_typetarget") %>%
  dplyr::select(-rowname)

Estimate_DT <- as.numeric(Estimate_DT)

p_DT <- as.data.frame(DT.gamm.summ$p.pv) %>%
  rownames_to_column() %>%
  filter(rowname == "data_typetarget") %>%
  dplyr::select(-rowname)

p_DT <- as.numeric(p_DT)
```

```{r GAMM output table, echo=FALSE, message=FALSE, warning=FALSE}

gamm.models.A <- rbind(PAT.gamm.A, PAQ.gamm.A, gamm.DT) 
dummy.T <- PAT.gamm.T %>%
  mutate(Model = "DT.gamm.0", Score = "", Edf = "", Difference = "",
                                                          Df = "", p.value = "", Sig. = "")
gamm.models.T <- rbind(PAT.gamm.T, PAQ.gamm.T, dummy.T) 
gamm.models.all <- cbind(gamm.models.A, gamm.models.T)
gamm.models.all <- gamm.models.all[,-8]
gamm.models.all <- gamm.models.all %>%
  mutate(Model = fct_recode(Model,
                            "PAT:Age" = "PAT.gamm.1_A",
                             "PAQ:Age" = "PAQ.gamm.1_A",
                            "PAT:Data type" = "DT.gamm.1"),
         p.value = ifelse(Sig. == "***", "<.001", p.value),
         p.value.1 = ifelse(Sig..1 == "***", "<.001", p.value.1)) %>%
  filter(Difference > 0 | Difference.1 > 0) %>%
  rename("Chi Sq" = "Difference",
         "Chi Sq.1" = "Difference.1",
         "p" = "p.value",
         "p.1" = "p.value.1") %>%
  mutate(".1" = row_number()) %>%
  dplyr::select(`.1`, Model, Df, `Chi Sq`, p, Df.1, `Chi Sq.1`, p.1)

```

```{r table-GAMM-outputs, echo=FALSE, message=FALSE, warning=FALSE}
cap="Outputs from nested model comparisons of GAMMs testing the effect of age on PAT and PAQ values in Actual and Target data (Models 1 and 2), and the effect of Data type on PAT values (Model 3). Model comparisons compared full models against those without parametric and smooth terms that included the variable being tested."
kable(gamm.models.all, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c",
      col.names=c(" ", "Model", "Df", "Chi Sq", "p", "Df", "Chi Sq", "p")) %>%
    kable_styling()%>%
  add_header_above(c(" "=2, "Actual"=3, "Target"=3))
```

```{r figure-GAMM-PAT, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}

{plot_smooth(PAT.gamm.1_A, view="AOP", rug=F, col="red",  
              ylim = c(-2,3),
              xlim = c(12,30),
              main = "Figure 1",
              xlab = "Age (months)",
              ylab = "PAT value (scaled)",
              hide.label = T)
plot_smooth(PAT.gamm.1_T, view="AOP", rug=F, col="blue", add=T, 
              ylim = c(-2,3),
              xlim = c(12,30),
              #main = "B: PAT, Target data",
              xlab = "Age (months)",
              ylab = "PAT value (scaled)",
              hide.label = T)}

cap <- sprintf("PAT values over time in Actual and Target data, weighted according to accumulative vocabulary size. Red line represents Actual values, blue line represents Target values; coloured bands represent 95%% CIs.")
```

```{r figure-GAMM-PAQ, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}

{plot_smooth(PAQ.gamm.1_A, view="AOP", rug=F, col="red",  
              ylim = c(-1,0.5),
              xlim = c(12,30),
              main = "Figure 2",
              xlab = "Age (months)",
              ylab = "PAQ values (scaled)",
              hide.label = T)
plot_smooth(PAQ.gamm.1_T, view="AOP", rug=F, col="blue", add=T, 
              ylim = c(-1,0.5),
              xlim = c(12,30),
              #main = "",
              xlab = "Age (months)",
              ylab = "PAQ values (scaled)",
              hide.label = T)}

cap <- sprintf("PAQ values over time in Actual and Target data, weighted according to accumulative vocabulary size. Red line represents Actual values, blue line represents Target values; coloured bands represent 95%% CIs. Both smooths are shown here for exploratory purposes.")
```

Outputs from model comparisons are shown in Table \@ref(tab:table-GAMM-outputs) (rows 1-2). Consistent with the interactions reported from the logistic regression models above, age had a significant effect on PAT values in both Actual and Target data. However, the PAQ x Age interaction shown in the regression models was not supported. Model smooths for both PAT and PAQ are plotted in Figures \@ref(fig:figure-GAMM-PAT) and \@ref(fig:figure-GAMM-PAQ); these plots show clear linear changes in PAT values over time, for both Actual and Target data. In support of the findings above, and contrary to the expectations set out in H2, in the Actual data (shown in red in Figure \@ref(fig:figure-GAMM-PAT)), PAT values were lower in earlier acquisition, and increased over time. Furthermore, the trajectory is identical for the Target data (shown in blue), which contrasts with the regression model outputs above. Again as suggested above, the trajectory for PAQ is negative, such that higher PAQ values occur at earlier age points.

### Data type comparisons

H3 predicted that systematicity would be stronger in Actual, compared to Target, data. We would therefore expect PAT values to be higher in Actual data overall, indicating more connectivity. This analysis only applies to PAT, given that the global network used to determine PAQ-like growth is generated from Target forms anyway; the expected substantial overlap in the two data types is shown in Figure \@ref(fig:figure-GAMM-PAQ). To test for an effect of Data type, GAMMs were used to account for any non-linearity in the data over time. Model structure was almost identical to that reported above, except that 1) Data type was included as a parametric term, with a difference smooth[^4] and a by-Data type random smooth for the effect of age; 2) the full dataset, incorporating Actual and Target forms together, was tested.

Results from a nested model comparison are shown in Table \@ref(tab:table-GAMM-outputs) (row 3). Data type had a significant effect on PAT values. A summary of the full model reveals that PAT values were significantly lower in the Target data than the Actual data (*b*=`r printnum(Estimate_DT)`, *p*`r printp(p_DT)`), thereby supporting H3. 

```{r difference-smooth-data-type, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}

plot_diff(DT.gamm.1, view="AOP", comp=list(data_type=c("target","actual")),
  main = "Figure 3",
  ylab = "Est. difference in scaled PAT values",
  xlab = "Age (months)",
  xlim = c(10,30),
  hide.label = TRUE)

cap <- sprintf("Difference smooth plot showing difference between scaled PAT values in Actual vs. Target forms from the GAMM model specified above. Shaded area shows 95%% confidence intervals, red line along x-axis indicates months in which
the difference between Actual and Target forms was significant.")
```

The difference of the two smooths is shown in Figure \@ref(fig:difference-smooth-data-type). The red line indicates periods where the two trajectories differed significantly from one another - from 15 months until the final time-point in the analysis. For clarity, the two smooths are visualised in Figure \@ref(fig:plotted-smooth-data-type) where the difference between the two trajectories is clear.

```{r plotted-smooth-data-type, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}

data_type_plot
cap <- sprintf("Smooth plot showing scaled PAT values in Actual vs. Target forms. Shaded areas show 95%% confidence intervals, lines indicate mean trajectories over time, coloured circles represent individual datapoints, jittered for visual clarity.")
```


# Discussion

```{r discussion calculations}

mean_PAT_P <- reg_dat %>% filter(age == (AOP-1) & corpus == "English") %>% group_by(data_type) %>% summarise(meanPAT = mean(PAT_scaled))
mean_PAT_L <- reg_dat %>% filter(age == (AOP-1) & corpus == "French") %>% group_by(data_type) %>% summarise(meanPAT = mean(PAT_scaled))

mean_PAT_diff_P <- (subset(mean_PAT_P, data_type == "actual")$meanPAT - subset(mean_PAT_P, data_type == "target")$meanPAT)*100
mean_PAT_diff_L <- (subset(mean_PAT_L, data_type == "actual")$meanPAT - subset(mean_PAT_L, data_type == "target")$meanPAT)*100

```

This study tested two established frameworks of network growth in the context of early phonological development: preferential attachment (PAT) and preferential acquisition (PAQ) [@fourtassi_growth_2020; @hills_longitudinal_2009; @siew_investigation_2020]. Using naturalistic data to quantify infants' realization of words, it was possible to establish similarity (or connectedness) across the phonological properties of infants' early words, and map how this changes over time. Based on previous analyses showing that infants' early productions tend to share phonological properties [e.g. @vihman_prosodic_2016; @waterson_child_1971; see also @vihman_emergence_2013], it was hypothesised that the early vocabulary would grow in a PAT-like manner (H1) -- that is, it should constitute dense clusters of similar-sounding forms -- and that acquisition should be most systematic earlier on in development (H2). Expanding on two key studies in this area [@fourtassi_growth_2020; @siew_investigation_2020], it was also predicted that a network consisting of infants' actual productions (that is, the child's *realization* of the target forms) should demonstrate more typical PAT-like growth than an equivalent network constituting just the target forms (H3). Two of these three hypotheses were supported by the data.

First, in support of H1, network growth models showed strong evidence for PAT-like growth in both Actual and Target data; newly-acquired words were produced in a similar way to existing words in the network, such that, in a given month, as-yet-unknown words that would connect to the most densely-clustered known words were more likely to be acquired in the next month. PAQ-like growth did not convincingly predict learning: Model 3 showed PAQ to be a significant predictor of word learning alongside PAT, but inspection of the model estimates showed that words with *lower* PAQ values were more likely to be acquired, and that this effect was only marginally significant. H2 predicted that PAT-like network growth would be stronger in earlier development, based on previous analyses that show infants' earliest words to be phonologically similar or even identical [e.g. @deuchar_bilingual_2000]. However, the opposite was true in this data set: in both Actual and Target data, earlier-acquired words tended to have *lower* PAT values, while later-acquired words had higher PAT values. Finally, in support of H3, PAT-like growth was more convincing for the Actual than the Target data: analysis of GAMM smooths revealed that Data type (Actual versus Target) accounted for significant variance in PAT values, whereby Target data had significantly lower PAT values than Actual data from very early on in the data (15 months).

It was surprising to find so little evidence for PAQ across the analyses, given that previous studies show more convincing evidence for PAQ overall, and given that PAT and PAQ are not mutually exclusive models of network growth. Amatuni and Bergelson [-@amatuni_semantic_2017] propose that PAT and PAQ could work together, such that PAQ may "[supplement] PAT by providing a structured sampling space for new word selection" (p.5). That is, a combination of PAT and PAQ would provide both internal (output-driven) and external (input-driven) roles in development. Indeed, acquisition is a dynamic and interactive process [@thelen_esther_dynamic_1996], with ample evidence showing the effects of the input on early word learning [@ambridge_ubiquity_2015; @rowe_longitudinal_2012]; it is to be expected that both models would be at work simultaneously during acquisition. It may be that this was not shown in the current data due to the fact that the regression models controlled for many external factors known to affect word learning -- input frequency, word length, word category, etc. -- which together could have accounted for much of the variability that otherwise would have been captured by PAQ growth values in this corpus.

The present analysis sheds new light on systematicity in early language acquisition, specifically regarding the role of PAT- and PAQ-like models of phonological development. Previous studies have drawn on age of acquisition data, using the target form as the index of production [@fourtassi_growth_2020; @siew_investigation_2020]. This has allowed study of vocabulary growth across a large sample, and findings have presented a new perspective on the role of phonological neighbourhoods in early acquisition. However, these analyses have not interrogated the role of *production*. By considering networks in relation to the way infants produce their early-acquired words, it has been possible to consider phonological network growth from a novel perspective. The findings presented here reveal a systematic approach to early phonological development, as infants exploit their existing production capacity to produce new words with familiar articulatory routines. These results support many previous studies that show lexical development to take place via the implementation of systematic structures and templates [@vihman_emergence_2013; @vihman_phonological_2019; @waterson_child_1971], and also model a new way of analysing phonological systematicity in infants' early productions, which can be extended to larger samples and applied to a wider variety of languages.

Given that Fourtassi and colleagues [-@fourtassi_growth_2020] analysed data from children of similar ages using the same subset of words (i.e. CDI words), we would expect the current findings to map on to their results, particularly in the analysis of Target data. And indeed, this is the area where we find the most evidence for PAQ-like network growth. However, their study consistently reveals stronger evidence for PAQ and so our results do not align as much as might be expected. This may reflect direct differences in the type of data used: in the present study, the order of acquisition (and thereby the model of network growth) reflects the chronological order of individual children's production. Month-by-month acquisition norms taken from thousands of children's CDIs model an 'average' order of acquisition, whereby words that *tend to* appear earlier in the developing lexicon are biased towards an earlier age of acquisition. Frank and colleagues [-@frank_variability_2021] report the first 10 words of infants acquiring American English, which (for stop consonants only) contain two instances of /m/, three each of /n/ and /d/, five /b/ and one /g/. In naturalistic production, however, a word's phonological form may prime the acquisition of other similar-sounding words: production of *baby* may be shortly followed by *bib* and *ball* [cf. @mccune_early_2001], while in vocabulary norms, acquisition of *baby*, *bib* and *ball* is represented at the group level. Vocabulary norming data thus represents an 'averaging out' of phonological connectedness across thousands of infants, creating a bias towards PAQ-like growth. Previous similar studies perhaps represent a more general, one-size-fits-all trajectory to lexical development, whereas these results capture individual clusters of connectivity as children acquire words that match the phonological characteristics of existing words in the lexicon. 

Indeed, studies of infants' early words show that, on a word-by-word basis, early-acquired forms tend to consist of the same set of consonants, in both target and actual forms. This reflects the child's 'selection' of early words to match their own consonant repertoire [@vihman_phonological_2019; @stoel-gammon_patterns_1984; @mccune_early_2001]. Given that these results show evidence for PAT-like growth in both Actual and Target data, it appears that infants are selectively acquiring forms that match their own production preferences, and are either producing these forms accurately (*selected*, in Vihman's terms) or *adapting* them to match their preferred output patterns. Within Vihman's framework, phonological development involves the selection or adaption of lexical units to fit a set of easily-accessible articulatory categories. That is, an infant systematically acts upon new understanding (i.e. acquired receptive vocabulary items) within the limitations of their development, selecting existing categories to deal with challenges presented in production. These are 'well-worn paths' that represent the stable and well-rehearsed production routines that drive selection, and later adaption, of infants' early word forms. In producing forms that are accessible and familiar to the child, they can 'rehearse' particular segments and structures, easing up memory and planning capacity for more flexible and variable production further down the line.

This study raises new questions for future analyses into systematicity in phonological development. While efforts were made to fully characterise the phonological content of infants' early productions -- through using distinctive features with Euclidean, rather than Levenshtein, distance, and observing Actual productions alongside Target forms -- still it was not possible to capture the full extent of systematicity, i.e. the presence of prosodic structures or templates [@vihman_phonological_2019]. Future work in this area should expand the analyses to consider the development and systematic implementation of templates. Furthermore, this analysis considers only two languages; it would be valuable to extend the approach to a wider variety of languages. Systematicity has been demonstrated across languages [@khattab_influence_2013; @szreder_acquisition_2013; @arnon_experience_2011], and so it should be possible to find cross-linguistic commonalities in network growth. Typological differences in network growth would raise questions about the cognitive reality of systematicity in phonological development. 

# Conclusion

When naturalistic data is considered within a networks account, we find evidence for PAT-like network growth, but not PAQ-like growth. English- and French-learning infants acquired words that would connect to the most highly-connected nodes in the existing network (PAT-like growth), and this became increasingly systematic over time. When we look at the target form of the words infants acquire and how they produce them, in both cases we see evidence to show that early acquisition is driven -- at least in part -- by preferences in the output. That is, infants acquire words that cluster together phonologically, and produce them systematically such that early production represents clusters of similar-sounding forms.


[^1]: A third model - Lure of the Associates - has also been considered in some studies [@hills_longitudinal_2009; @siew_investigation_2020] but will not be considered here as there is no conclusive evidence for this model in the development literature.

[^2]: Note that these are not mutually exclusive.

[^3]: The Providence corpus [@demuth_word-minimality_2006] includes six children (three boys). One child was later diagnosed with a developmental disorder and so is omitted from this analysis. The Lyon corpus [@demuth_katherine_prosodically-conditioned_2008] includes five children (two boys) but one of the datasets (Marilyn) is not fully transcribed and is therefore excluded from this analysis.

[^4]: Difference smooths account for the fact that the different levels of the smooth might differ in their non-linearity; in this instance, the by-Data type difference smooth accounts for the possibility that Actual and Target data may have different trajectories. 

\newpage

# References
```{r create_r-references}
r_refs(file="r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs"></div>
\end{longtable}
\endgroup
